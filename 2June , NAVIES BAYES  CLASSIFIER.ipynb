{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc516b4-25b3-4640-b3b3-bdb6eeca3c11",
   "metadata": {},
   "source": [
    "# NAVIE BAYES "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c4ef4-f8a1-4c0a-9454-372120c5c40e",
   "metadata": {},
   "source": [
    "Naive Bayes is a machine learning algorithm that uses probability to predict the class of a data point. It assumes that all features are independent of each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8c705-b0a7-44af-b6ac-ab706de1e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMULA ==>  P(A∣B)=P(B∣A)⋅P(A)\n",
    "                    _______\n",
    "                     P(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5855f23f-28ee-4223-a5df-f4f07274d21c",
   "metadata": {},
   "source": [
    "## HOW IT WORKS \n",
    "\n",
    "Convert data to probabilities.\n",
    "\n",
    "Use Bayes’ Theorem to calculate the probability of each class.\n",
    "\n",
    "Predict the class with the highest probability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c045c1-3133-4f97-bace-f92b858781dd",
   "metadata": {},
   "source": [
    "## TYPES OF NAVIE BAYES \n",
    "\n",
    "Gaussian Naive Bayes: For continuous data (assumes normal distribution).\n",
    "\n",
    "Multinomial Naive Bayes: For discrete count data (e.g., text classification).\n",
    "\n",
    "Bernoulli Naive Bayes: For binary/boolean features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cbb10-212e-4eca-bd6d-e577aa8a0766",
   "metadata": {},
   "source": [
    " #### Laplace Smoothing (also called Add-One Smoothing)\n",
    "Laplace Smoothing is a technique used in Naive Bayes to handle the problem of zero probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ddc83-0584-43f1-8dee-21f9f0f3f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "P(word∣class)= count of word in class+1\n",
    "             _____________________________\n",
    "                total words in class+V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5c1446-911d-42ec-9ec1-c5265b64daf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messsage: cheap meds now\n",
      "predicted class: ['spam', 'spam', 'spam', 'not spam', 'not spam', 'not spam']\n",
      "probabilites: spam = 1.00,not spam = 0.00\n",
      "messsage: schedule a meeting\n",
      "predicted class: ['spam', 'spam', 'spam', 'not spam', 'not spam', 'not spam']\n",
      "probabilites: spam = 0.00,not spam = 1.00\n",
      "messsage: project scheduel\n",
      "predicted class: ['spam', 'spam', 'spam', 'not spam', 'not spam', 'not spam']\n",
      "probabilites: spam = 0.06,not spam = 0.94\n",
      "messsage: discount online pills\n",
      "predicted class: ['spam', 'spam', 'spam', 'not spam', 'not spam', 'not spam']\n",
      "probabilites: spam = 1.00,not spam = 0.00\n",
      "messsage: meeting now\n",
      "predicted class: ['spam', 'spam', 'spam', 'not spam', 'not spam', 'not spam']\n",
      "probabilites: spam = 0.35,not spam = 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# dataset\n",
    "texts = [\n",
    "    \"buy cheap meds now\",\n",
    "    \"cheap pills online\",\n",
    "    \"get discount now\",\n",
    "    \"meeting at office\",\n",
    "    \"project discussion\",\n",
    "    \"schedule a meeting\"\n",
    "]\n",
    "\n",
    "labels = [\"spam\" , \"spam\" , \"spam\" , \"not spam\" , \"not spam\" , \"not spam\" ]\n",
    "\n",
    "# create a model pipeline\n",
    "\n",
    "model = make_pipeline(CountVectorizer() , MultinomialNB(alpha = 0.1))  # laplace smoothing with alpha=1\n",
    "\n",
    "# train the model\n",
    "model.fit(texts,labels)\n",
    "\n",
    "#test messages\n",
    "\n",
    "test_messages = [\n",
    "    \"cheap meds now\",\n",
    "    \"schedule a meeting\",\n",
    "    \"project scheduel\",\n",
    "    \"discount online pills\",\n",
    "    \"meeting now\"\n",
    "]\n",
    "\n",
    "# make predictions\n",
    "predicted = model.predict(test_messages)\n",
    "probs = model.predict_proba(test_messages)\n",
    "\n",
    "#display results\n",
    "\n",
    "for msg,label,prob in zip(test_messages , predicted , probs):\n",
    "    print(f\"messsage: {msg}\")\n",
    "    print(f\"predicted class: {labels}\")\n",
    "    print(f\"probabilites: spam = {prob[model.classes_.tolist().index('spam')]:.2f},not spam = {prob[model.classes_.tolist().index('not spam')]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c287bad-4248-48a9-94f1-df9ebf6570de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
