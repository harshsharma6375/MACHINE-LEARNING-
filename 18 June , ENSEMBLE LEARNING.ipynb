{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d20ddb-c1c3-496a-859e-07993c05e1cc",
   "metadata": {},
   "source": [
    "## ENSEMBLE  LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d3cea1-a288-4791-b08f-e44fab599768",
   "metadata": {},
   "source": [
    "It is a machine learning technique . That involves combining multiple individual models \n",
    "known as Base learnes to make predictions or decisions . \n",
    "\n",
    "The main idea: Behind Ensemble learning is that by combinig the predicitons of multiple models , the overall performance can be improved compare to lossing a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f1bb8-a5e8-4a37-9b24-bbc8bdb464ac",
   "metadata": {},
   "source": [
    "## TECHNIQUES\n",
    "\n",
    "1) BAGGING --> It send for bootstrap aggregating , It involves creating multiple subset of the training data through bootstarpping . Trainig is separate based learner on each subset and then combinig their prediction . The most common example of bagging is the randomn forest algorithm which combines multiple decision trees . \n",
    "\n",
    "\n",
    "2)BOOSTING --> It is an iterative and ensemble methods . That focuses on training weak learners sequentially and giving more importance to the instance that were misclassified by previous learners  in boosting each base learner is trained to correct the mistakes made by the previous learners ,  eg -> ADA boost , EXE boost ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07aaecc-82a3-4a98-8d6c-48b9a759fde9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7238cbc8-27ba-4302-9436-71146bd8cd42",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ca0057-e0c0-4d4f-8ee2-bdbbc9e5ea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a list to store the base learners\n",
    "base_learners = []\n",
    "\n",
    "# Number of base learners (decision trees)\n",
    "num_base_learners = 10\n",
    "\n",
    "# Train the base learners\n",
    "for i in range(num_base_learners):\n",
    "    # Create a bootstrap sample of the training data\n",
    "    bootstrap_indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    X_bootstrap = X_train[bootstrap_indices]\n",
    "    y_bootstrap = y_train[bootstrap_indices]\n",
    "\n",
    "# Create and train a base learner (Random Forest)\n",
    "base_learner = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "base_learner.fit(X_bootstrap, y_bootstrap)\n",
    "# Add the trained base learner to the list\n",
    "base_learners.append(base_learner)\n",
    "\n",
    "# Make predictions with each base learner\n",
    "base_predictions = []\n",
    "for base_learner in base_learners:\n",
    "    y_pred = base_learner.predict(X_test)\n",
    "    base_predictions.append(y_pred)\n",
    "# combined the prediction using majority voting\n",
    "ensemble_predictions =np.round(np.mean(base_predictions,axis=0))\n",
    "# Calculate the accuracy of the ensemble predictions\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(\"Ensemble Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b656b5-2ebf-42b2-8dd7-d39d935c742f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
